{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9ba7f14-6e50-4116-ad12-e6fe47df9a82",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2da8340c-7b07-4d33-a392-b8bbfb43ef2b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_path = '/home/jupyter/novice/vlm.jsonl'\n",
    "images_source_dir = Path(\"/home/jupyter/novice/images\")\n",
    "dataset_dir = Path(\"/home/jupyter/til-24-base/derrick/dataset\")\n",
    "\n",
    "# Create directories for train, val, and test sets\n",
    "train_images_dir = dataset_dir / \"images/train\"\n",
    "val_images_dir = dataset_dir / \"images/val\"\n",
    "train_labels_dir = dataset_dir / \"labels/train\"\n",
    "val_labels_dir = dataset_dir / \"labels/val\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d608e010-dd4b-41ce-84c7-e3463d059b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directories if they don't exist\n",
    "for directory in [train_images_dir, val_images_dir, train_labels_dir, val_labels_dir]:\n",
    "    os.makedirs(directory, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43774b24-bdf0-4251-b4af-32f9bd115402",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the JSONL file\n",
    "dataset = load_dataset('json', data_files='/home/jupyter/novice/vlm.jsonl', split='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7d5ff53-ac14-4f72-b952-5633f223d8b9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['image', 'annotations'],\n",
      "    num_rows: 5000\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4865a7e-8bb6-48b9-913f-33ca9000985e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Split the dataset into train, validation, and test sets\n",
    "train_val_test_split = dataset.train_test_split(test_size=0.2, seed=42)\n",
    "\n",
    "# Get the splits\n",
    "train_dataset = train_val_test_split['train']\n",
    "val_dataset = train_val_test_split['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "361c682c-ea65-43ca-a6f2-637506a30277",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['image', 'annotations'],\n",
      "    num_rows: 4000\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3db05a89-f010-453e-9c75-ac068023ffe6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['image', 'annotations'],\n",
      "    num_rows: 1000\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ca56fae-f2e0-4cab-8480-adb449a77bb2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'image_1183.jpg'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_dataset['image'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "55911f4a-7901-4766-a155-458c55254e38",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize a dictionary to map captions to class indices\n",
    "class_map = {}\n",
    "class_counter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "601fa4eb-7dd9-45b2-9615-731fbb1bd640",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define a function to convert bounding box format\n",
    "def convert_bbox_to_yolo(bbox, img_width, img_height):\n",
    "    x_center = (bbox[0] + bbox[2] / 2) / img_width\n",
    "    y_center = (bbox[1] + bbox[3] / 2) / img_height\n",
    "    width = bbox[2] / img_width\n",
    "    height = bbox[3] / img_height\n",
    "    return x_center, y_center, width, height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "21eb8c83-2ede-4bea-8ab1-4e1afdf47f81",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def process_split(dataset, images_dir, labels_dir):\n",
    "    global class_counter\n",
    "    for obj in dataset:\n",
    "        image_filename = obj['image']\n",
    "        annotations = obj['annotations']\n",
    "        \n",
    "        # Source image path\n",
    "        image_path = images_source_dir / image_filename\n",
    "        \n",
    "        # Copy image to target directory\n",
    "        target_image_path = images_dir / image_filename\n",
    "        if not target_image_path.exists():\n",
    "            shutil.copy(image_path, target_image_path)\n",
    "\n",
    "        # Get image dimensions\n",
    "        img = Image.open(image_path)\n",
    "        img_width, img_height = img.size\n",
    "\n",
    "        # Create corresponding label file\n",
    "        label_file_path = labels_dir / f\"{os.path.splitext(image_filename)[0]}.txt\"\n",
    "        if not label_file_path.exists():\n",
    "            with open(label_file_path, 'w') as label_file:\n",
    "                for ann in annotations:\n",
    "                    caption = ann['caption']\n",
    "                    if caption not in class_map:\n",
    "                        class_map[caption] = class_counter\n",
    "                        class_counter += 1\n",
    "                    class_idx = class_map[caption]\n",
    "                    bbox = ann['bbox']\n",
    "                    yolo_bbox = convert_bbox_to_yolo(bbox, img_width, img_height)\n",
    "                    label_file.write(f\"{class_idx} \" + \" \".join(map(str, yolo_bbox)) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a48b8a82-a29d-4d44-a044-8ed1581114fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process each split\n",
    "process_split(train_dataset, train_images_dir, train_labels_dir)\n",
    "process_split(val_dataset, val_images_dir, val_labels_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f853ea13-1862-4d21-8caf-1116b59716c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def save_classmap(dataset):\n",
    "    global class_counter\n",
    "    for obj in dataset:\n",
    "        image_filename = obj['image']\n",
    "        annotations = obj['annotations']\n",
    "        \n",
    "        for ann in annotations:\n",
    "            caption = ann['caption']\n",
    "            if caption not in class_map:\n",
    "                print(caption)\n",
    "                class_map[caption] = class_counter\n",
    "                class_counter += 1            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "83e83013-9cd0-4152-9365-71698fc5e376",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "save_classmap(train_dataset)\n",
    "save_classmap(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e9fc2f94-340e-4ddb-9d2d-b8a4046ed293",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset split and label creation completed successfully!\n"
     ]
    }
   ],
   "source": [
    "# Save class map to a file\n",
    "class_map_file = dataset_dir / \"class_map.txt\"\n",
    "with class_map_file.open('w') as f:\n",
    "    for caption, idx in class_map.items():\n",
    "        f.write(f\"{caption}: {idx}\\n\")\n",
    "\n",
    "print(\"Dataset split and label creation completed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "68f79641-a568-4087-86a1-6112c7ea2f97",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset split and label creation completed successfully!\n",
      "YOLOv8 configuration file created successfully!\n"
     ]
    }
   ],
   "source": [
    "# Create the YOLOv8 configuration file\n",
    "config_content = f\"\"\"train: {train_images_dir}  # train images directory\n",
    "val: {val_images_dir}  # validation images directory\n",
    "nc: {len(class_map)}  # number of classes\n",
    "names: {list(class_map.keys())}  # class names\n",
    "\"\"\"\n",
    "\n",
    "config_path = dataset_dir / \"model_config.yaml\"\n",
    "with config_path.open('w') as f:\n",
    "    f.write(config_content)\n",
    "\n",
    "print(\"Dataset split and label creation completed successfully!\")\n",
    "print(\"YOLOv8 configuration file created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f057c899-cccd-4d53-95a9-c1976fdedd16",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m120",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m120"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
